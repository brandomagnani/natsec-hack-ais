{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ais_updates_in_ports():\n",
    "    # filter AIS updates table down to entries that are close to ports\n",
    "    pass\n",
    "\n",
    "\n",
    "# pick a \"flagged\" port\n",
    "# get all ships that have been in that port - flag them\n",
    "# get all ship encounters with flagged ships, flag them too\n",
    "\n",
    "# 1. compute all encounters\n",
    "\n",
    "# 2. compute all flagged-port visits\n",
    "\n",
    "# 3. compute graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            mmsi        lat         lon          start_time  \\\n",
      "0      367387860  29.951921  -90.387626 2024-01-01 00:00:00   \n",
      "1      367194680  38.576065  -90.219979 2024-01-01 00:00:00   \n",
      "2      368111380  37.904210 -122.372424 2024-01-01 00:00:00   \n",
      "3      367009930  40.730698  -74.012630 2024-01-01 00:00:00   \n",
      "4      366941830  29.731084  -95.049651 2024-01-01 00:00:00   \n",
      "...          ...        ...         ...                 ...   \n",
      "22744  367299580  26.555353  -97.429779 2024-01-05 21:58:46   \n",
      "22745  368221490  30.058834  -93.369630 2024-01-05 21:58:48   \n",
      "22746  367061980  40.640499  -74.129270 2024-01-05 21:59:00   \n",
      "22747  367170330  29.936361  -90.334758 2024-01-05 21:59:19   \n",
      "22748  261036090  18.340948  -64.794153 2024-01-05 21:59:33   \n",
      "\n",
      "                 end_time  \n",
      "0     2024-01-01 07:16:41  \n",
      "1     2024-01-01 06:34:40  \n",
      "2     2024-01-01 04:12:59  \n",
      "3     2024-01-01 02:14:09  \n",
      "4     2024-01-01 05:10:30  \n",
      "...                   ...  \n",
      "22744 2024-01-05 23:59:56  \n",
      "22745 2024-01-05 23:59:29  \n",
      "22746 2024-01-05 23:59:11  \n",
      "22747 2024-01-05 23:59:29  \n",
      "22748 2024-01-05 23:59:59  \n",
      "\n",
      "[22749 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "def get_encounters_for_port(port_id: str):\n",
    "    pass\n",
    "\n",
    "import duckdb\n",
    "\n",
    "def get_stops_for_vessel(mmsi: str):\n",
    "    # query ais table for this ship\n",
    "    # for when it has had velocity (column `sog`) = 0\n",
    "    # for 2-8 hours\n",
    "\n",
    "    con = duckdb.connect()\n",
    "\n",
    "    con.execute(\"\"\"\n",
    "        CREATE TABLE ais_data AS\n",
    "        SELECT * FROM read_parquet('./data/parquet/AIS_*.parquet')\n",
    "    \"\"\")\n",
    "\n",
    "    statement = \"\"\"\n",
    "    WITH vessel_sog_zero AS (\n",
    "  SELECT \n",
    "    mmsi,\n",
    "    timestamp,\n",
    "    lat,\n",
    "    lon,\n",
    "    sog,\n",
    "    -- Row number over time for each vessel\n",
    "    ROW_NUMBER() OVER (PARTITION BY mmsi ORDER BY timestamp) \n",
    "      - ROW_NUMBER() OVER (PARTITION BY mmsi, CASE WHEN sog <= 0.5 THEN 1 ELSE 0 END ORDER BY timestamp) AS grp\n",
    "  FROM \n",
    "    ais_data\n",
    "),\n",
    "\n",
    "pause_groups AS (\n",
    "  SELECT\n",
    "    mmsi,\n",
    "    MIN(timestamp) AS start_time,\n",
    "    MAX(timestamp) AS end_time,\n",
    "    AVG(lat) AS avg_lat,\n",
    "    AVG(lon) AS avg_lon,\n",
    "    COUNT(*) AS point_count\n",
    "  FROM\n",
    "    vessel_sog_zero\n",
    "  WHERE\n",
    "    sog <= 0.5  -- consider low SOG as paused (threshold can be adjusted)\n",
    "  GROUP BY\n",
    "    mmsi, grp\n",
    "  HAVING\n",
    "    (MAX(timestamp) - MIN(timestamp)) BETWEEN INTERVAL '2 hours' AND INTERVAL '8 hours'\n",
    ")\n",
    "\n",
    "SELECT\n",
    "  mmsi,\n",
    "  avg_lat AS lat,\n",
    "  avg_lon AS lon,\n",
    "  start_time,\n",
    "  end_time\n",
    "FROM\n",
    "  pause_groups\n",
    "ORDER BY\n",
    "  start_time;\n",
    "    \"\"\"\n",
    "    print( \n",
    "        con.execute(statement).fetch_df()\n",
    "    )\n",
    "\n",
    "get_stops_for_vessel(\"hi\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/f6/sqqvc2dx4d524h3rq_b16j0h0000gn/T/ipykernel_39872/2989330745.py:53: DeprecationWarning: `pl.count()` is deprecated. Please use `pl.len()` instead.\n",
      "  pl.count().alias(\"point_count\")\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "from pathlib import Path\n",
    "from datetime import timedelta\n",
    "\n",
    "\n",
    "def get_stops_for_vessel(mmsi: str | list[str] | None = None) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Find periods where vessels have stopped (very low speed) for 2-8 hours.\n",
    "    \n",
    "    Args:\n",
    "        mmsi: Optional vessel MMSI to filter for a specific vessel\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with vessel stops including location and timing information\n",
    "    \"\"\"\n",
    "    # Read all AIS data files\n",
    "    # Read all AIS data files\n",
    "    # Read all AIS data files\n",
    "    df = pl.concat([\n",
    "        pl.read_parquet(f) \n",
    "        for f in Path('./data/parquet').glob('AIS_*.parquet')\n",
    "    ])\n",
    "    \n",
    "    if mmsi and isinstance(mmsi, str):\n",
    "        df = df.filter(pl.col(\"mmsi\") == mmsi)\n",
    "    elif mmsi and isinstance(mmsi, list):\n",
    "        df = df.filter(pl.col(\"mmsi\").is_in(mmsi))\n",
    "    \n",
    "    # Consider vessel stopped when SOG <= 0.5 knots\n",
    "    df = df.with_columns([\n",
    "        # Convert timestamp to datetime if it isn't already\n",
    "        pl.col(\"timestamp\").cast(pl.Datetime).alias(\"timestamp\"),\n",
    "        # Flag for stopped vessels\n",
    "        (pl.col(\"sog\") <= 0.5).alias(\"is_stopped\")\n",
    "    ]).sort([\"mmsi\", \"timestamp\"])\n",
    "    \n",
    "    # Create groups of consecutive stops using rank difference method\n",
    "    df = df.with_columns([\n",
    "        pl.col(\"timestamp\").rank().over(\"mmsi\").alias(\"row_nr\"),\n",
    "        pl.col(\"timestamp\").rank().over([\"mmsi\", \"is_stopped\"]).alias(\"group_row_nr\")\n",
    "    ]).with_columns([\n",
    "        (pl.col(\"row_nr\") - pl.col(\"group_row_nr\")).alias(\"stop_group\")\n",
    "    ])\n",
    "    \n",
    "    # Group by vessel and stop group to find extended stops\n",
    "    stops = df.filter(pl.col(\"is_stopped\")).group_by(\n",
    "        [\"mmsi\", \"stop_group\"]\n",
    "    ).agg([\n",
    "        pl.col(\"timestamp\").min().alias(\"start_time\"),\n",
    "        pl.col(\"timestamp\").max().alias(\"end_time\"),\n",
    "        pl.col(\"lat\").mean().alias(\"lat\"),\n",
    "        pl.col(\"lon\").mean().alias(\"lon\"),\n",
    "        pl.count().alias(\"point_count\")\n",
    "    ]).with_columns([\n",
    "        (pl.col(\"end_time\") - pl.col(\"start_time\")).alias(\"duration\")\n",
    "    ]).filter(\n",
    "        # Filter for stops between 2 and 8 hours\n",
    "        (pl.col(\"duration\") >= timedelta(hours=2)) \n",
    "        & (pl.col(\"duration\") <= timedelta(hours=8))\n",
    "    ).sort(\"start_time\")\n",
    "    \n",
    "    return stops.select([\n",
    "        \"mmsi\",\n",
    "        \"lat\",\n",
    "        \"lon\",\n",
    "        \"start_time\",\n",
    "        \"end_time\",\n",
    "        \"duration\",\n",
    "        \"point_count\"\n",
    "    ])\n",
    "\n",
    "\n",
    "    \n",
    "stops = get_stops_for_vessel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/f6/sqqvc2dx4d524h3rq_b16j0h0000gn/T/ipykernel_39872/1950675439.py:51: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n",
      "  cross_joined = cross_joined.with_columns([\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (61, 13)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>mmsi</th><th>lat</th><th>lon</th><th>start_time</th><th>end_time</th><th>duration</th><th>point_count</th><th>port_uid</th><th>port_name</th><th>region_name</th><th>country_code</th><th>world_water_body</th><th>distance_to_port_nm</th></tr><tr><td>i64</td><td>f64</td><td>f64</td><td>datetime[μs]</td><td>datetime[μs]</td><td>duration[μs]</td><td>u32</td><td>f64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>f64</td></tr></thead><tbody><tr><td>366996610</td><td>28.950537</td><td>-95.333915</td><td>2024-01-01 00:00:08</td><td>2024-01-01 02:23:49</td><td>2h 23m 41s</td><td>124</td><td>9250.0</td><td>&quot;Freeport&quot;</td><td>&quot;US Gulf Coast -- 8650&quot;</td><td>&quot;United States&quot;</td><td>&quot;Gulf of Mexico; North Atlantic…</td><td>0.044459</td></tr><tr><td>367564240</td><td>29.733433</td><td>-95.19967</td><td>2024-01-01 00:01:48</td><td>2024-01-01 06:40:50</td><td>6h 39m 2s</td><td>129</td><td>9210.0</td><td>&quot;Norsworthy&quot;</td><td>&quot;US Gulf Coast -- 8650&quot;</td><td>&quot;United States&quot;</td><td>&quot;Gulf of Mexico; North Atlantic…</td><td>0.01821</td></tr><tr><td>366516370</td><td>40.668308</td><td>-74.016655</td><td>2024-01-01 00:29:30</td><td>2024-01-01 02:31:48</td><td>2h 2m 18s</td><td>59</td><td>7630.0</td><td>&quot;Brooklyn&quot;</td><td>&quot;United States E Coast -- 6585&quot;</td><td>&quot;United States&quot;</td><td>&quot;North Atlantic Ocean&quot;</td><td>0.098504</td></tr><tr><td>368008060</td><td>25.782255</td><td>-80.183027</td><td>2024-01-01 02:00:08</td><td>2024-01-01 05:21:07</td><td>3h 20m 59s</td><td>58</td><td>8640.0</td><td>&quot;Miami&quot;</td><td>&quot;United States E Coast -- 6585&quot;</td><td>&quot;United States&quot;</td><td>&quot;North Atlantic Ocean&quot;</td><td>0.066808</td></tr><tr><td>775998212</td><td>25.781977</td><td>-80.183608</td><td>2024-01-01 03:11:26</td><td>2024-01-01 06:04:51</td><td>2h 53m 25s</td><td>46</td><td>8640.0</td><td>&quot;Miami&quot;</td><td>&quot;United States E Coast -- 6585&quot;</td><td>&quot;United States&quot;</td><td>&quot;North Atlantic Ocean&quot;</td><td>0.082771</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>368308420</td><td>25.950004</td><td>-97.400805</td><td>2024-01-05 16:26:40</td><td>2024-01-05 23:58:59</td><td>7h 32m 19s</td><td>93</td><td>9340.0</td><td>&quot;Brownsville&quot;</td><td>&quot;US Gulf Coast -- 8650&quot;</td><td>&quot;United States&quot;</td><td>&quot;Gulf of Mexico; North Atlantic…</td><td>0.043462</td></tr><tr><td>368088250</td><td>28.950818</td><td>-95.334942</td><td>2024-01-05 17:23:24</td><td>2024-01-05 23:59:55</td><td>6h 36m 31s</td><td>341</td><td>9250.0</td><td>&quot;Freeport&quot;</td><td>&quot;US Gulf Coast -- 8650&quot;</td><td>&quot;United States&quot;</td><td>&quot;Gulf of Mexico; North Atlantic…</td><td>0.097762</td></tr><tr><td>368233290</td><td>31.150295</td><td>-81.499981</td><td>2024-01-05 17:23:39</td><td>2024-01-05 23:59:49</td><td>6h 36m 10s</td><td>344</td><td>8550.0</td><td>&quot;Brunswick&quot;</td><td>&quot;United States E Coast -- 6585&quot;</td><td>&quot;United States&quot;</td><td>&quot;North Atlantic Ocean&quot;</td><td>0.017728</td></tr><tr><td>338144207</td><td>27.815195</td><td>-97.400857</td><td>2024-01-05 18:14:09</td><td>2024-01-05 20:55:36</td><td>2h 41m 27s</td><td>26</td><td>9300.0</td><td>&quot;Corpus Christi&quot;</td><td>&quot;US Gulf Coast -- 8650&quot;</td><td>&quot;United States&quot;</td><td>&quot;Gulf of Mexico; North Atlantic…</td><td>0.099435</td></tr><tr><td>366995670</td><td>28.950372</td><td>-95.33393</td><td>2024-01-05 21:40:45</td><td>2024-01-05 23:46:46</td><td>2h 6m 1s</td><td>108</td><td>9250.0</td><td>&quot;Freeport&quot;</td><td>&quot;US Gulf Coast -- 8650&quot;</td><td>&quot;United States&quot;</td><td>&quot;Gulf of Mexico; North Atlantic…</td><td>0.038495</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (61, 13)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ mmsi      ┆ lat       ┆ lon       ┆ start_tim ┆ … ┆ region_na ┆ country_c ┆ world_wat ┆ distance │\n",
       "│ ---       ┆ ---       ┆ ---       ┆ e         ┆   ┆ me        ┆ ode       ┆ er_body   ┆ _to_port │\n",
       "│ i64       ┆ f64       ┆ f64       ┆ ---       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ _nm      │\n",
       "│           ┆           ┆           ┆ datetime[ ┆   ┆ str       ┆ str       ┆ str       ┆ ---      │\n",
       "│           ┆           ┆           ┆ μs]       ┆   ┆           ┆           ┆           ┆ f64      │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ 366996610 ┆ 28.950537 ┆ -95.33391 ┆ 2024-01-0 ┆ … ┆ US Gulf   ┆ United    ┆ Gulf of   ┆ 0.044459 │\n",
       "│           ┆           ┆ 5         ┆ 1         ┆   ┆ Coast --  ┆ States    ┆ Mexico;   ┆          │\n",
       "│           ┆           ┆           ┆ 00:00:08  ┆   ┆ 8650      ┆           ┆ North     ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆ Atlantic… ┆          │\n",
       "│ 367564240 ┆ 29.733433 ┆ -95.19967 ┆ 2024-01-0 ┆ … ┆ US Gulf   ┆ United    ┆ Gulf of   ┆ 0.01821  │\n",
       "│           ┆           ┆           ┆ 1         ┆   ┆ Coast --  ┆ States    ┆ Mexico;   ┆          │\n",
       "│           ┆           ┆           ┆ 00:01:48  ┆   ┆ 8650      ┆           ┆ North     ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆ Atlantic… ┆          │\n",
       "│ 366516370 ┆ 40.668308 ┆ -74.01665 ┆ 2024-01-0 ┆ … ┆ United    ┆ United    ┆ North     ┆ 0.098504 │\n",
       "│           ┆           ┆ 5         ┆ 1         ┆   ┆ States E  ┆ States    ┆ Atlantic  ┆          │\n",
       "│           ┆           ┆           ┆ 00:29:30  ┆   ┆ Coast --  ┆           ┆ Ocean     ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ 6585      ┆           ┆           ┆          │\n",
       "│ 368008060 ┆ 25.782255 ┆ -80.18302 ┆ 2024-01-0 ┆ … ┆ United    ┆ United    ┆ North     ┆ 0.066808 │\n",
       "│           ┆           ┆ 7         ┆ 1         ┆   ┆ States E  ┆ States    ┆ Atlantic  ┆          │\n",
       "│           ┆           ┆           ┆ 02:00:08  ┆   ┆ Coast --  ┆           ┆ Ocean     ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ 6585      ┆           ┆           ┆          │\n",
       "│ 775998212 ┆ 25.781977 ┆ -80.18360 ┆ 2024-01-0 ┆ … ┆ United    ┆ United    ┆ North     ┆ 0.082771 │\n",
       "│           ┆           ┆ 8         ┆ 1         ┆   ┆ States E  ┆ States    ┆ Atlantic  ┆          │\n",
       "│           ┆           ┆           ┆ 03:11:26  ┆   ┆ Coast --  ┆           ┆ Ocean     ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ 6585      ┆           ┆           ┆          │\n",
       "│ …         ┆ …         ┆ …         ┆ …         ┆ … ┆ …         ┆ …         ┆ …         ┆ …        │\n",
       "│ 368308420 ┆ 25.950004 ┆ -97.40080 ┆ 2024-01-0 ┆ … ┆ US Gulf   ┆ United    ┆ Gulf of   ┆ 0.043462 │\n",
       "│           ┆           ┆ 5         ┆ 5         ┆   ┆ Coast --  ┆ States    ┆ Mexico;   ┆          │\n",
       "│           ┆           ┆           ┆ 16:26:40  ┆   ┆ 8650      ┆           ┆ North     ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆ Atlantic… ┆          │\n",
       "│ 368088250 ┆ 28.950818 ┆ -95.33494 ┆ 2024-01-0 ┆ … ┆ US Gulf   ┆ United    ┆ Gulf of   ┆ 0.097762 │\n",
       "│           ┆           ┆ 2         ┆ 5         ┆   ┆ Coast --  ┆ States    ┆ Mexico;   ┆          │\n",
       "│           ┆           ┆           ┆ 17:23:24  ┆   ┆ 8650      ┆           ┆ North     ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆ Atlantic… ┆          │\n",
       "│ 368233290 ┆ 31.150295 ┆ -81.49998 ┆ 2024-01-0 ┆ … ┆ United    ┆ United    ┆ North     ┆ 0.017728 │\n",
       "│           ┆           ┆ 1         ┆ 5         ┆   ┆ States E  ┆ States    ┆ Atlantic  ┆          │\n",
       "│           ┆           ┆           ┆ 17:23:39  ┆   ┆ Coast --  ┆           ┆ Ocean     ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ 6585      ┆           ┆           ┆          │\n",
       "│ 338144207 ┆ 27.815195 ┆ -97.40085 ┆ 2024-01-0 ┆ … ┆ US Gulf   ┆ United    ┆ Gulf of   ┆ 0.099435 │\n",
       "│           ┆           ┆ 7         ┆ 5         ┆   ┆ Coast --  ┆ States    ┆ Mexico;   ┆          │\n",
       "│           ┆           ┆           ┆ 18:14:09  ┆   ┆ 8650      ┆           ┆ North     ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆ Atlantic… ┆          │\n",
       "│ 366995670 ┆ 28.950372 ┆ -95.33393 ┆ 2024-01-0 ┆ … ┆ US Gulf   ┆ United    ┆ Gulf of   ┆ 0.038495 │\n",
       "│           ┆           ┆           ┆ 5         ┆   ┆ Coast --  ┆ States    ┆ Mexico;   ┆          │\n",
       "│           ┆           ┆           ┆ 21:40:45  ┆   ┆ 8650      ┆           ┆ North     ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆ Atlantic… ┆          │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import polars as pl\n",
    "from datetime import timedelta\n",
    "from pathlib import Path\n",
    "import math\n",
    "\n",
    "\n",
    "def haversine_distance(lat1: float, lon1: float, lat2: float, lon2: float) -> float:\n",
    "    \"\"\"\n",
    "    Calculate the great circle distance between two points \n",
    "    on the earth (specified in decimal degrees)\n",
    "    Returns distance in nautical miles\n",
    "    \"\"\"\n",
    "    # Convert decimal degrees to radians\n",
    "    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n",
    "    \n",
    "    # Haversine formula\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = math.sin(dlat/2)**2 + math.cos(lat1) * math.cos(lat2) * math.sin(dlon/2)**2\n",
    "    c = 2 * math.asin(math.sqrt(a))\n",
    "    # Radius of earth in nautical miles\n",
    "    r = 3440  # Earth's radius in nautical miles\n",
    "    return c * r\n",
    "\n",
    "\n",
    "def filter_for_proximity_to_port(stops: pl.DataFrame, threshold: float, port_ids: list[str] | None = None) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Filter vessel stops based on proximity to ports.\n",
    "    \n",
    "    Args:\n",
    "        stops: DataFrame containing vessel stops with lat/lon coordinates\n",
    "        threshold: Distance threshold in nautical miles\n",
    "        port_ids: Optional list of port UIDs to filter for specific ports\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with stops that are within threshold distance of ports,\n",
    "        including port information\n",
    "    \"\"\"\n",
    "    # Load ports data\n",
    "    ports = pl.read_parquet(\"./data/parquet/ports.parquet\")\n",
    "    \n",
    "    # Filter ports if specific IDs are provided\n",
    "    if port_ids:\n",
    "        ports = ports.filter(pl.col(\"uid\").is_in(port_ids))\n",
    "    \n",
    "    # Create a cross join between stops and ports\n",
    "    # This will allow us to calculate distances between all combinations\n",
    "    cross_joined = stops.join(ports, how=\"cross\")\n",
    "    \n",
    "    # Calculate distances using haversine formula\n",
    "    cross_joined = cross_joined.with_columns([\n",
    "        pl.struct([\"lat\", \"lon\", \"lat_right\", \"lon_right\"]).map_elements(\n",
    "            lambda x: haversine_distance(x[\"lat\"], x[\"lon\"], x[\"lat_right\"], x[\"lon_right\"])\n",
    "        ).alias(\"distance_nm\")\n",
    "    ])\n",
    "    \n",
    "    # Filter for stops within threshold distance of any port\n",
    "    nearby_stops = cross_joined.filter(pl.col(\"distance_nm\") <= threshold)\n",
    "    \n",
    "    # For each stop, keep only the closest port\n",
    "    result = nearby_stops.group_by([\n",
    "        \"mmsi\", \"lat\", \"lon\", \"start_time\", \"end_time\", \"duration\", \"point_count\"\n",
    "    ]).agg([\n",
    "        pl.col(\"uid\").alias(\"port_uid\").first(),\n",
    "        pl.col(\"name\").alias(\"port_name\").first(),\n",
    "        pl.col(\"region_name\").first(),\n",
    "        pl.col(\"country_code\").first(),\n",
    "        pl.col(\"world_water_body\").first(),\n",
    "        pl.col(\"distance_nm\").min().alias(\"distance_to_port_nm\")\n",
    "    ]).sort([\"start_time\", \"mmsi\"])\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "filter_for_proximity_to_port(stops, 0.1, port_ids=[i for i in range(10000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/f6/sqqvc2dx4d524h3rq_b16j0h0000gn/T/ipykernel_39872/2989330745.py:53: DeprecationWarning: `pl.count()` is deprecated. Please use `pl.len()` instead.\n",
      "  pl.count().alias(\"point_count\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joined (3, 16)\n",
      "distances (3, 17)\n",
      "overlap calcuulated (1, 19)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 8)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>mmsi1</th><th>mmsi2</th><th>overlap_start</th><th>overlap_end</th><th>lat</th><th>lon</th><th>distance_meters</th><th>overlap_duration</th></tr><tr><td>i64</td><td>i64</td><td>datetime[μs]</td><td>datetime[μs]</td><td>f64</td><td>f64</td><td>f64</td><td>duration[μs]</td></tr></thead><tbody><tr><td>368008060</td><td>775998212</td><td>2024-01-01 03:11:26</td><td>2024-01-01 05:21:07</td><td>25.782255</td><td>-80.183027</td><td>65.809725</td><td>2h 9m 41s</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 8)\n",
       "┌───────────┬───────────┬────────────┬────────────┬───────────┬────────────┬───────────┬───────────┐\n",
       "│ mmsi1     ┆ mmsi2     ┆ overlap_st ┆ overlap_en ┆ lat       ┆ lon        ┆ distance_ ┆ overlap_d │\n",
       "│ ---       ┆ ---       ┆ art        ┆ d          ┆ ---       ┆ ---        ┆ meters    ┆ uration   │\n",
       "│ i64       ┆ i64       ┆ ---        ┆ ---        ┆ f64       ┆ f64        ┆ ---       ┆ ---       │\n",
       "│           ┆           ┆ datetime[μ ┆ datetime[μ ┆           ┆            ┆ f64       ┆ duration[ │\n",
       "│           ┆           ┆ s]         ┆ s]         ┆           ┆            ┆           ┆ μs]       │\n",
       "╞═══════════╪═══════════╪════════════╪════════════╪═══════════╪════════════╪═══════════╪═══════════╡\n",
       "│ 368008060 ┆ 775998212 ┆ 2024-01-01 ┆ 2024-01-01 ┆ 25.782255 ┆ -80.183027 ┆ 65.809725 ┆ 2h 9m 41s │\n",
       "│           ┆           ┆ 03:11:26   ┆ 05:21:07   ┆           ┆            ┆           ┆           │\n",
       "└───────────┴───────────┴────────────┴────────────┴───────────┴────────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stops_a = get_stops_for_vessel(mmsi=[368008060])\n",
    "df_stops = get_stops_for_vessel(mmsi=[775998212])\n",
    "\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "\n",
    "# Parameters\n",
    "max_distance_meters = 500  # e.g., vessels must be within 500 meters\n",
    "min_overlap_seconds = 300  # e.g., overlapping for at least 5 minutes\n",
    "\n",
    "# Assume df already loaded with columns: mmsi, lat, lon, start_time, end_time\n",
    "\n",
    "# --- Helper: Haversine Distance ---\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    R = 6371000  # Earth radius in meters\n",
    "    lat1 = np.radians(lat1)\n",
    "    lon1 = np.radians(lon1)\n",
    "    lat2 = np.radians(lat2)\n",
    "    lon2 = np.radians(lon2)\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2\n",
    "    return 2 * R * np.arcsin(np.sqrt(a))\n",
    "\n",
    "# --- Cross Join vessels with themselves ---\n",
    "df1 = df_stops_a.with_columns(mmsi1=pl.col(\"mmsi\"))\n",
    "df2 = df_stops.with_columns(mmsi2=pl.col(\"mmsi\"))\n",
    "\n",
    "pairs = df1.join(df2, how=\"cross\")\n",
    "\n",
    "print(\"joined\", pairs.shape)\n",
    "\n",
    "# --- Filter out self-matches ---\n",
    "pairs = pairs.filter(pl.col(\"mmsi1\") < pl.col(\"mmsi2\"))\n",
    "\n",
    "# --- Compute distance between vessel locations ---\n",
    "pairs = pairs.with_columns(\n",
    "    pl.Series(\n",
    "        \"distance_meters\",\n",
    "        haversine(\n",
    "            pairs[\"lat\"], pairs[\"lon\"],\n",
    "            pairs[\"lat_right\"], pairs[\"lon_right\"]\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"distances\", pairs.shape)\n",
    "\n",
    "# --- Filter by spatial proximity ---\n",
    "pairs = pairs.filter(pl.col(\"distance_meters\") <= max_distance_meters)\n",
    "\n",
    "# --- Compute temporal overlap ---\n",
    "pairs = pairs.with_columns([\n",
    "    pl.max_horizontal([\"start_time\", \"start_time_right\"]).alias(\"overlap_start\"),\n",
    "    pl.min_horizontal([\"end_time\", \"end_time_right\"]).alias(\"overlap_end\")\n",
    "])\n",
    "\n",
    "print(\"overlap calcuulated\", pairs.shape)\n",
    "\n",
    "pairs = pairs.with_columns(\n",
    "    (pl.col(\"overlap_end\") - pl.col(\"overlap_start\")).alias(\"overlap_duration\")\n",
    ")\n",
    "\n",
    "# --- Keep only positive, sufficient overlaps ---\n",
    "pairs = pairs.filter(\n",
    "    (pl.col(\"overlap_duration\") > pl.duration(seconds=0)) &\n",
    "    (pl.col(\"overlap_duration\") >= pl.duration(seconds=min_overlap_seconds))\n",
    ")\n",
    "\n",
    "# --- Select output columns ---\n",
    "result = pairs.select([\n",
    "    \"mmsi1\",\n",
    "    \"mmsi2\",\n",
    "    \"overlap_start\",\n",
    "    \"overlap_end\",\n",
    "    \"lat\", \"lon\",\n",
    "    \"distance_meters\",\n",
    "    \"overlap_duration\"\n",
    "])\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Count]\n",
       "Index: []"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con = duckdb.connect()\n",
    "con.execute(\"\"\"\n",
    "        CREATE TABLE ais_data AS\n",
    "        SELECT * FROM read_parquet('./data/parquet/AIS_*.parquet')\n",
    "    \"\"\")\n",
    "\n",
    "statement=\"\"\"-- Install and load spatial extension if not already\n",
    "INSTALL spatial;\n",
    "LOAD spatial;\n",
    "\n",
    "-- Drop materialized view if exists\n",
    "DROP VIEW IF EXISTS vessel_stops;\n",
    "\n",
    "-- Create new materialized view\n",
    "CREATE VIEW vessel_stops AS\n",
    "\n",
    "WITH preprocessed AS (\n",
    "  SELECT \n",
    "    mmsi,\n",
    "    timestamp,\n",
    "    lat,\n",
    "    lon,\n",
    "    sog,\n",
    "    -- Integer bucket lat/lon (~100m precision)\n",
    "    CAST(FLOOR(lat * 1110) AS INTEGER) AS lat_bucket,\n",
    "    CAST(FLOOR(lon * 1110) AS INTEGER) AS lon_bucket,\n",
    "    -- Define if vessel is moving very slowly (sog <= 0.2)\n",
    "    CASE WHEN sog <= 0.5 THEN 1 ELSE 0 END AS is_stopped\n",
    "  FROM \n",
    "    ais_data\n",
    "),\n",
    "\n",
    "grouped AS (\n",
    "  SELECT \n",
    "    *,\n",
    "    -- Trick: Create session groups by detecting breaks in stop sequences\n",
    "    ROW_NUMBER() OVER (PARTITION BY mmsi ORDER BY timestamp)\n",
    "      - ROW_NUMBER() OVER (PARTITION BY mmsi, lat_bucket, lon_bucket, is_stopped ORDER BY timestamp)\n",
    "    AS stop_group\n",
    "  FROM \n",
    "    preprocessed\n",
    "),\n",
    "\n",
    "stops AS (\n",
    "  SELECT \n",
    "    mmsi,\n",
    "    lat_bucket,\n",
    "    lon_bucket,\n",
    "    MIN(timestamp) AS start_time,\n",
    "    MAX(timestamp) AS end_time,\n",
    "    MAX(timestamp) - MIN(timestamp) AS duration\n",
    "  FROM \n",
    "    grouped\n",
    "  WHERE \n",
    "    is_stopped = 1\n",
    "  GROUP BY \n",
    "    mmsi, lat_bucket, lon_bucket, stop_group\n",
    "  HAVING \n",
    "    MAX(timestamp) - MIN(timestamp) BETWEEN INTERVAL '2 minutes' AND INTERVAL '8 hours'\n",
    ")\n",
    "\n",
    "SELECT \n",
    "  mmsi,\n",
    "  lat_bucket,\n",
    "  lon_bucket,\n",
    "  start_time,\n",
    "  end_time,\n",
    "  duration\n",
    "FROM \n",
    "  stops\n",
    "ORDER BY \n",
    "  start_time;\"\"\"\n",
    "\n",
    "\n",
    "con.execute(statement).fetch_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from sqlalchemy import text\n",
    "\n",
    "\n",
    "def get_stops_for_vessel(mmsi: str) -> list[dict[str, any]]:\n",
    "    statement = f\"\"\"\n",
    "    SELECT * FROM vessel_stops WHERE mmsi = {mmsi}\n",
    "    \"\"\"\n",
    "\n",
    "    return con.execute(text(statement)).fetchall()\n",
    "\n",
    "def get_vessels_for_stop_and_time(stop_location: tuple[float, float], start_time: datetime.datetime | None = None, end_time: datetime.datetime | None = None) -> list[str]:\n",
    "    # use this to construct graph\n",
    "    # scenario spec-start < start and spec-end > end (spec fully contains)\n",
    "    # scenario spec-start < start and spec-end < end (spec starts earlier)\n",
    "    # scenario spec-start > start and spec-end > end (spec ends later)\n",
    "    # scenario spec-start > start and spec-end < end (spec fully contained)\n",
    "\n",
    "    # negative scenarios\n",
    "    # scenario spec-end < start\n",
    "    # scenario spec-start > end\n",
    "    statement = f\"SELECT mmsi FROM vessel_stops WHERE lat_bucket = {stop_location[1]} AND lon_bucket = {stop_location[0]} AND NOT ({end_time} < date_start  OR {start_time} > date_end)\"\n",
    "    return con.execute(statement).fetchall()\n",
    "\n",
    "def get_vessels_for_stop_location(stop_location: tuple[float, float]) -> list[str]:\n",
    "    # use this to get vessels from flagged ports\n",
    "    return con.execute(\"SELECT mmsi FROM vessel_stops WHERE lat_bucket = ? AND lon_bucket = ?\", stop_location).fetchall()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
